///////////////////////////////////////////////////////////////////////////////////////////////////
// QUICK REFERENCE GUIDE - å¿«é€Ÿå‚è€ƒæŒ‡å—
// ğŸ“ ç”¨é€”: DATï¼ˆæ•°æ®ä¼ è¾“ï¼‰æ€§èƒ½æµ‹è¯•å•å…ƒæµ‹è¯•å¤´æ–‡ä»¶æ¡†æ¶
// ğŸ”„ æµç¨‹: User Story â†’ Acceptance Criteria â†’ Test Cases â†’ Implementation
// ğŸ“‚ åˆ†ç±»: DataPerformance - ä¸“æ³¨äºDATæ•°æ®ä¼ è¾“çš„æ€§èƒ½ç‰¹æ€§å’Œä¼˜åŒ–åœºæ™¯éªŒè¯
// ğŸ¯ é‡ç‚¹: ååé‡ã€å»¶è¿Ÿã€èµ„æºåˆ©ç”¨ç‡ã€å¹¶å‘æ€§èƒ½å’Œæ€§èƒ½ä¼˜åŒ–çš„å®Œæ•´æ€§éªŒè¯
// Reference Unit Testing Templates in UT_FreelyDrafts.cxx when needed.
///////////////////////////////////////////////////////////////////////////////////////////////////

#ifndef UT_DATAPERFORMANCE_H
#define UT_DATAPERFORMANCE_H

#include <algorithm>
#include <atomic>
#include <chrono>
#include <cmath>
#include <limits>
#include <mutex>
#include <thread>
#include <vector>

#include "_UT_IOC_Common.h"

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF OVERVIEW OF THIS UNIT TESTING FILE===============================================
/**
 * @brief
 *  éªŒè¯IOCæ¡†æ¶ä¸­DATï¼ˆæ•°æ®ä¼ è¾“ï¼‰çš„æ€§èƒ½ç‰¹æ€§å’Œä¼˜åŒ–èƒ½åŠ›ï¼Œä¸“æ³¨äºååé‡ã€å»¶è¿Ÿã€
 *  èµ„æºåˆ©ç”¨ç‡ä»¥åŠå„ç§æ€§èƒ½ä¼˜åŒ–åœºæ™¯çš„å®Œæ•´æ€§éªŒè¯ã€‚
 *
 *-------------------------------------------------------------------------------------------------
 *++DATæ€§èƒ½æµ‹è¯•éªŒè¯æ•°æ®ä¼ è¾“è¿‡ç¨‹ä¸­çš„æ€§èƒ½æŒ‡æ ‡å’Œä¼˜åŒ–æ•ˆæœï¼Œæœ¬æµ‹è¯•æ–‡ä»¶å…³æ³¨æ€§èƒ½ç›¸å…³åœºæ™¯ï¼š
 *
 *  æ€§èƒ½éªŒè¯èŒƒå›´ï¼š
 *  - ğŸš€ ååé‡æµ‹è¯•: å•ä½æ—¶é—´å†…æ•°æ®ä¼ è¾“é‡ã€æ‰¹é‡ä¼ è¾“èƒ½åŠ›
 *  - â±ï¸ å»¶è¿Ÿæµ‹è¯•: ç«¯åˆ°ç«¯ä¼ è¾“å»¶è¿Ÿã€APIè°ƒç”¨å“åº”æ—¶é—´
 *  - ğŸ’¾ èµ„æºåˆ©ç”¨: å†…å­˜ä½¿ç”¨æ•ˆç‡ã€CPUå ç”¨ç‡ã€çº¿ç¨‹èµ„æºç®¡ç†
 *  - ğŸ”„ å¹¶å‘æ€§èƒ½: å¤šçº¿ç¨‹ä¼ è¾“ã€å¹¶å‘è¿æ¥ã€èµ„æºç«äº‰æ€§èƒ½
 *  - ğŸ“ˆ æ‰©å±•æ€§èƒ½: è´Ÿè½½å¢åŠ æ—¶çš„æ€§èƒ½è¡¨ç°ã€ç³»ç»Ÿå®¹é‡é™åˆ¶
 *  - ğŸ¯ ä¼˜åŒ–éªŒè¯: ç¼“å†²ä¼˜åŒ–ã€æµæ§ä¼˜åŒ–ã€é›¶æ‹·è´ç­‰ä¼˜åŒ–æœºåˆ¶
 *
 *  å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼š
 *  - Throughput: æ•°æ®ååé‡ (MB/s, packets/s)
 *  - Latency: ä¼ è¾“å»¶è¿Ÿ (milliseconds, microseconds)
 *  - CPU Usage: CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
 *  - Memory Usage: å†…å­˜ä½¿ç”¨é‡å’Œå†…å­˜æ•ˆç‡
 *  - Concurrent Capacity: å¹¶å‘å¤„ç†èƒ½åŠ›
 *  - Resource Efficiency: èµ„æºåˆ©ç”¨æ•ˆç‡
 *
 *  ä¸åŒ…æ‹¬ï¼š
 *  - åŠŸèƒ½æ­£ç¡®æ€§æµ‹è¯•ï¼ˆDataTypical è¦†ç›–ï¼‰
 *  - è¾¹ç•Œæ¡ä»¶æµ‹è¯•ï¼ˆDataBoundary è¦†ç›–ï¼‰
 *  - çŠ¶æ€è½¬æ¢æµ‹è¯•ï¼ˆDataState è¦†ç›–ï¼‰
 *  - ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•ï¼ˆDataRobust è¦†ç›–ï¼‰
 *
 *  å‚è€ƒæ–‡æ¡£ï¼š
 *  - IOC_Data.c: æ•°æ®ä¼ è¾“APIå®ç°å’Œæ€§èƒ½ä¼˜åŒ–
 *  - IOC_SrvProtoFifo: FIFOåè®®çš„æ€§èƒ½ç‰¹æ€§
 *  - ç³»ç»Ÿæ€§èƒ½éœ€æ±‚è§„æ ¼ä¹¦
 */
//======>END OF OVERVIEW OF THIS UNIT TESTING FILE=================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF USER STORY=======================================================================
/**************************************************************************************************
 * @brief ã€User Storyã€‘
 *
 *  US-1: AS a high-throughput DAT application developer,
 *    I WANT to verify that IOC_sendDAT/IOC_recvDAT operations achieve optimal throughput,
 *   SO THAT I can ensure maximum data transfer rates under various payload sizes
 *      AND validate batch transfer efficiency for bulk data operations,
 *      AND implement high-performance data streaming solutions.
 *
 *  US-2: AS a low-latency DAT application developer,
 *    I WANT to verify that DAT operations maintain minimal end-to-end latency,
 *   SO THAT I can ensure real-time data delivery requirements are met
 *      AND validate API call response times are within acceptable limits,
 *      AND implement time-critical data communication systems.
 *
 *  US-3: AS a resource-constrained DAT application developer,
 *    I WANT to verify that DAT operations optimize memory and CPU resource usage,
 *   SO THAT I can ensure efficient resource utilization in embedded systems
 *      AND validate memory allocation patterns and prevent memory leaks,
 *      AND implement resource-efficient data transfer mechanisms.
 *
 *  US-4: AS a concurrent DAT application developer,
 *    I WANT to verify that DAT operations scale efficiently with concurrent usage,
 *   SO THAT I can ensure performance remains stable under multi-threaded load
 *      AND validate concurrent connection handling capabilities,
 *      AND implement scalable multi-client data distribution systems.
 *
 *  US-5: AS a DAT optimization developer,
 *    I WANT to verify that performance optimization features work effectively,
 *   SO THAT I can ensure buffering, flow control, and zero-copy optimizations deliver benefits
 *      AND validate that NODROP guarantees don't significantly impact performance,
 *      AND implement advanced performance tuning mechanisms.
 *
 *  US-6: AS a DAT system capacity planner,
 *    I WANT to verify system behavior under increasing load conditions,
 *   SO THAT I can determine maximum system capacity and performance limits
 *      AND validate graceful degradation under overload conditions,
 *      AND implement proper capacity planning for production deployments.
 *
 *************************************************************************************************/
//======>END OF USER STORY=========================================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//=======>BEGIN OF ACCEPTANCE CRITERIA=============================================================
/**************************************************************************************************
 * @brief ã€Acceptance Criteriaã€‘
 *
 * [@US-1] High-throughput DAT operations verification
 *  AC-1: GIVEN a DAT link configured for bulk data transfer,
 *         WHEN sending large payloads (1KB to 1MB) repeatedly,
 *         THEN throughput should achieve target rates (e.g., >100MB/s for large payloads)
 *              AND throughput should scale with payload size efficiently
 *              AND bulk transfer operations should maintain consistent performance.
 *
 *  AC-2: GIVEN multiple DAT streams operating simultaneously,
 *         WHEN each stream transfers data at high rates,
 *         THEN aggregate throughput should scale linearly with stream count
 *              AND individual stream performance should remain stable
 *              AND resource contention should not cause significant degradation.
 *
 *  AC-3: GIVEN DAT batch operations with varying batch sizes,
 *         WHEN processing batches from small (10 items) to large (10K items),
 *         THEN batch processing efficiency should improve with larger batches
 *              AND memory allocation overhead should be minimized
 *              AND batch completion time should scale sub-linearly.
 *
 *---------------------------------------------------------------------------------------------------
 * [@US-2] Low-latency DAT operations verification
 *  AC-1: GIVEN a DAT link optimized for minimal latency,
 *         WHEN sending small messages (64B to 4KB) with immediate delivery,
 *         THEN end-to-end latency should be within target limits (e.g., <1ms)
 *              AND latency should be consistent across message sizes
 *              AND jitter should be minimal for real-time applications.
 *
 *  AC-2: GIVEN IOC_sendDAT and IOC_recvDAT API calls,
 *         WHEN measuring API call response times,
 *         THEN API latency should be minimal (e.g., <100Î¼s for small messages)
 *              AND API performance should not degrade with system load
 *              AND blocking operations should have predictable timing.
 *
 *  AC-3: GIVEN DAT callback mechanisms for immediate data delivery,
 *         WHEN data arrives and triggers callbacks,
 *         THEN callback invocation latency should be minimal
 *              AND callback processing should not block other operations
 *              AND callback queue management should maintain low latency.
 *
 *---------------------------------------------------------------------------------------------------
 * [@US-3] Resource-efficient DAT operations verification
 *  AC-1: GIVEN DAT operations running on resource-constrained systems,
 *         WHEN monitoring memory usage during data transfer,
 *         THEN memory allocation should be efficient and predictable
 *              AND memory leaks should not occur during sustained operations
 *              AND buffer reuse should minimize allocation overhead.
 *
 *  AC-2: GIVEN DAT operations under CPU monitoring,
 *         WHEN transferring data at various rates,
 *         THEN CPU usage should scale proportionally with data volume
 *              AND CPU overhead per byte should decrease with larger transfers
 *              AND system responsiveness should be maintained.
 *
 *  AC-3: GIVEN DAT thread and handle resource management,
 *         WHEN creating and destroying multiple connections,
 *         THEN thread pool utilization should be efficient
 *              AND handle allocation should not leak resources
 *              AND resource cleanup should be complete and timely.
 *
 *---------------------------------------------------------------------------------------------------
 * [@US-4] Concurrent DAT operations verification
 *  AC-1: GIVEN multiple threads performing DAT operations simultaneously,
 *         WHEN thread count increases from 1 to N (e.g., 100),
 *         THEN throughput should scale efficiently with thread count
 *              AND thread contention should not cause significant overhead
 *              AND thread safety should be maintained without data corruption.
 *
 *  AC-2: GIVEN concurrent DAT senders and receivers,
 *         WHEN multiple clients connect to a single service,
 *         THEN service should handle concurrent connections efficiently
 *              AND per-client performance should remain stable
 *              AND resource sharing should be fair across clients.
 *
 *  AC-3: GIVEN DAT operations under concurrent stress testing,
 *         WHEN simulating real-world concurrent usage patterns,
 *         THEN system should maintain stability under high concurrency
 *              AND performance degradation should be gradual and predictable
 *              AND no deadlocks or race conditions should occur.
 *
 *---------------------------------------------------------------------------------------------------
 * [@US-5] DAT optimization features verification
 *  AC-1: GIVEN DAT buffering optimization features,
 *         WHEN comparing buffered vs unbuffered operations,
 *         THEN buffered operations should show improved throughput
 *              AND buffer size tuning should demonstrate performance gains
 *              AND optimal buffer sizes should be determinable.
 *
 *  AC-2: GIVEN DAT flow control mechanisms (NODROP guarantees),
 *         WHEN receiver cannot keep up with sender,
 *         THEN flow control should prevent data loss with minimal performance impact
 *              AND sender backpressure should be handled efficiently
 *              AND system should recover quickly when receiver catches up.
 *
 *  AC-3: GIVEN zero-copy and memory optimization features,
 *         WHEN enabled for large data transfers,
 *         THEN memory copy overhead should be significantly reduced
 *              AND CPU usage should decrease for large payload transfers
 *              AND memory bandwidth utilization should be optimal.
 *
 *---------------------------------------------------------------------------------------------------
 * [@US-6] DAT system capacity and scalability verification
 *  AC-1: GIVEN DAT system under increasing load conditions,
 *         WHEN load increases from low to maximum capacity,
 *         THEN system should maintain acceptable performance until limits
 *              AND maximum capacity should be clearly determinable
 *              AND performance degradation should be graceful beyond limits.
 *
 *  AC-2: GIVEN DAT system approaching resource limits,
 *         WHEN system resources (memory, threads, connections) reach capacity,
 *         THEN system should handle resource exhaustion gracefully
 *              AND error reporting should indicate specific resource constraints
 *              AND system should recover when resources become available.
 *
 *  AC-3: GIVEN long-running DAT operations for endurance testing,
 *         WHEN system operates under sustained load for extended periods,
 *         THEN performance should remain stable over time
 *              AND no performance degradation should occur due to resource leaks
 *              AND system should handle sustained operations reliably.
 */
//=======>END OF ACCEPTANCE CRITERIA================================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF TEST CASE DEFINITIONS============================================================
/**************************************************************************************************
 * @brief ã€Test Casesã€‘
 *
 * [@AC-1,US-1] High-throughput bulk data transfer
 *  TC-1:
 *      @[Name]: verifyBulkDataThroughput_byLargePayloads_expectOptimalRates
 *      @[Purpose]: éªŒè¯å¤§è´Ÿè½½æ•°æ®ä¼ è¾“çš„ååé‡æ€§èƒ½
 *      @[Brief]: ä½¿ç”¨1KBåˆ°1MBè´Ÿè½½æµ‹è¯•ååé‡ï¼ŒéªŒè¯æ€§èƒ½ç›®æ ‡è¾¾æˆ
 *      @[Throughput_Focus]: æµ‹è¯•æœ€å¤§æ•°æ®ä¼ è¾“é€Ÿç‡å’Œè´Ÿè½½å¤§å°å¯¹æ€§èƒ½çš„å½±å“
 *
 *  TC-2:
 *      @[Name]: verifyThroughputScaling_byPayloadSize_expectLinearScaling
 *      @[Purpose]: éªŒè¯ååé‡éšè´Ÿè½½å¤§å°çš„æ‰©å±•æ€§
 *      @[Brief]: æµ‹è¯•ä¸åŒè´Ÿè½½å¤§å°ä¸‹çš„ååé‡æ‰©å±•æ€§
 *      @[Scaling_Focus]: æµ‹è¯•æ€§èƒ½éšæ•°æ®å¤§å°çš„æ‰©å±•è§„å¾‹
 *
 * [@AC-2,US-1] Multi-stream concurrent throughput
 *  TC-1:
 *      @[Name]: verifyMultiStreamThroughput_byConcurrentStreams_expectLinearScaling
 *      @[Purpose]: éªŒè¯å¤šæµå¹¶å‘ä¼ è¾“çš„ååé‡æ‰©å±•æ€§
 *      @[Brief]: åŒæ—¶è¿è¡Œå¤šä¸ªæ•°æ®æµï¼ŒéªŒè¯èšåˆååé‡çš„çº¿æ€§æ‰©å±•
 *      @[Concurrent_Focus]: æµ‹è¯•å¹¶å‘æ•°æ®æµçš„æ€§èƒ½å½±å“
 *
 * [@AC-1,US-2] Low-latency message delivery
 *  TC-1:
 *      @[Name]: verifyEndToEndLatency_bySmallMessages_expectMinimalDelay
 *      @[Purpose]: éªŒè¯å°æ¶ˆæ¯ç«¯åˆ°ç«¯ä¼ è¾“å»¶è¿Ÿ
 *      @[Brief]: æµ‹è¯•64Båˆ°4KBæ¶ˆæ¯çš„ä¼ è¾“å»¶è¿Ÿï¼ŒéªŒè¯å®æ—¶æ€§è¦æ±‚
 *      @[Latency_Focus]: æµ‹è¯•ä½å»¶è¿Ÿæ•°æ®ä¼ è¾“èƒ½åŠ›
 *
 *  TC-2:
 *      @[Name]: verifyAPIResponseTime_byCallLatency_expectMicrosecondLevel
 *      @[Purpose]: éªŒè¯APIè°ƒç”¨å“åº”æ—¶é—´
 *      @[Brief]: æµ‹é‡IOC_sendDAT/IOC_recvDATçš„APIè°ƒç”¨å»¶è¿Ÿ
 *      @[API_Focus]: æµ‹è¯•APIçº§åˆ«çš„æ€§èƒ½ç‰¹æ€§
 *
 * [@AC-1,US-3] Memory and CPU resource efficiency
 *  TC-1:
 *      @[Name]: verifyMemoryEfficiency_byAllocationPatterns_expectOptimalUsage
 *      @[Purpose]: éªŒè¯å†…å­˜ä½¿ç”¨æ•ˆç‡å’Œåˆ†é…æ¨¡å¼
 *      @[Brief]: ç›‘æ§æ•°æ®ä¼ è¾“è¿‡ç¨‹ä¸­çš„å†…å­˜åˆ†é…å’Œé‡Šæ”¾æ•ˆç‡
 *      @[Memory_Focus]: æµ‹è¯•å†…å­˜ä½¿ç”¨ä¼˜åŒ–æ•ˆæœ
 *
 *  TC-2:
 *      @[Name]: verifyCPUUtilization_byDataVolume_expectProportionalUsage
 *      @[Purpose]: éªŒè¯CPUä½¿ç”¨ç‡ä¸æ•°æ®é‡çš„æ¯”ä¾‹å…³ç³»
 *      @[Brief]: æµ‹é‡ä¸åŒæ•°æ®é‡ä¸‹çš„CPUä½¿ç”¨ç‡
 *      @[CPU_Focus]: æµ‹è¯•CPUèµ„æºåˆ©ç”¨æ•ˆç‡
 *
 * [@AC-1,US-4] Concurrent operations performance
 *  TC-1:
 *      @[Name]: verifyConcurrentThreadPerformance_byMultiThreading_expectLinearScaling
 *      @[Purpose]: éªŒè¯å¤šçº¿ç¨‹å¹¶å‘æ“ä½œçš„æ€§èƒ½æ‰©å±•æ€§
 *      @[Brief]: å¢åŠ çº¿ç¨‹æ•°é‡ï¼Œæµ‹è¯•å¹¶å‘æ€§èƒ½æ‰©å±•æ€§
 *      @[Threading_Focus]: æµ‹è¯•å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„æ€§èƒ½è¡¨ç°
 *
 *  TC-2:
 *      @[Name]: verifyMultiClientPerformance_byConcurrentConnections_expectFairSharing
 *      @[Purpose]: éªŒè¯å¤šå®¢æˆ·ç«¯å¹¶å‘è¿æ¥çš„æ€§èƒ½å…¬å¹³æ€§
 *      @[Brief]: æµ‹è¯•å¤šå®¢æˆ·ç«¯åŒæ—¶è¿æ¥æ—¶çš„æ€§èƒ½åˆ†é…
 *      @[MultiClient_Focus]: æµ‹è¯•å¹¶å‘å®¢æˆ·ç«¯çš„èµ„æºå…¬å¹³åˆ†é…
 *
 * [@AC-1,US-5] Performance optimization features
 *  TC-1:
 *      @[Name]: verifyBufferingOptimization_byBufferSizeTuning_expectPerformanceGains
 *      @[Purpose]: éªŒè¯ç¼“å†²ä¼˜åŒ–å¯¹æ€§èƒ½çš„æå‡æ•ˆæœ
 *      @[Brief]: æ¯”è¾ƒä¸åŒç¼“å†²åŒºå¤§å°å¯¹ä¼ è¾“æ€§èƒ½çš„å½±å“
 *      @[Buffering_Focus]: æµ‹è¯•ç¼“å†²æœºåˆ¶çš„æ€§èƒ½ä¼˜åŒ–æ•ˆæœ
 *
 *  TC-2:
 *      @[Name]: verifyZeroCopyOptimization_byLargeTransfers_expectReducedOverhead
 *      @[Purpose]: éªŒè¯é›¶æ‹·è´ä¼˜åŒ–çš„æ€§èƒ½æå‡
 *      @[Brief]: æµ‹è¯•é›¶æ‹·è´æœºåˆ¶å¯¹å¤§æ•°æ®ä¼ è¾“çš„æ€§èƒ½å½±å“
 *      @[ZeroCopy_Focus]: æµ‹è¯•é›¶æ‹·è´ä¼˜åŒ–çš„å®é™…æ•ˆæœ
 *
 * [@AC-1,US-6] System capacity and scalability
 *  TC-1:
 *      @[Name]: verifySystemCapacity_byIncreasingLoad_expectGracefulLimits
 *      @[Purpose]: éªŒè¯ç³»ç»Ÿå®¹é‡é™åˆ¶å’Œä¼˜é›…é™çº§
 *      @[Brief]: é€æ­¥å¢åŠ ç³»ç»Ÿè´Ÿè½½ï¼Œç¡®å®šæœ€å¤§å®¹é‡å’Œæ€§èƒ½è¾¹ç•Œ
 *      @[Capacity_Focus]: æµ‹è¯•ç³»ç»Ÿæœ€å¤§æ‰¿è½½èƒ½åŠ›
 *
 *  TC-2:
 *      @[Name]: verifyEndurancePerformance_byLongRunning_expectStablePerformance
 *      @[Purpose]: éªŒè¯é•¿æœŸè¿è¡Œçš„æ€§èƒ½ç¨³å®šæ€§
 *      @[Brief]: é•¿æ—¶é—´è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼ŒéªŒè¯æ€§èƒ½ç¨³å®šæ€§
 *      @[Endurance_Focus]: æµ‹è¯•é•¿æœŸè¿è¡Œçš„æ€§èƒ½ä¸€è‡´æ€§
 *
 *************************************************************************************************/
//======>END OF TEST CASE DEFINITIONS==============================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF PERFORMANCE TESTING INFRASTRUCTURE===============================================
/**
 * @brief æ€§èƒ½æµ‹è¯•åŸºç¡€è®¾æ–½
 *        æä¾›æ€§èƒ½æµ‹é‡ã€æ•°æ®æ”¶é›†ã€ç»Ÿè®¡åˆ†æç­‰åŠŸèƒ½
 */

// ===== PERFORMANCE METRICS COLLECTION =====
/**
 * @brief æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„
 *        ç»Ÿä¸€çš„æ€§èƒ½æ•°æ®æ”¶é›†å’Œåˆ†æç»“æ„
 */
typedef struct PerformanceMetrics {
    // Throughput metrics
    double BytesPerSecond{0.0};          // å­—èŠ‚æ¯ç§’ååé‡
    double MessagesPerSecond{0.0};       // æ¶ˆæ¯æ¯ç§’ååé‡
    double OperationsPerSecond{0.0};     // æ“ä½œæ¯ç§’é¢‘ç‡
    size_t TotalBytesTransferred{0};     // æ€»ä¼ è¾“å­—èŠ‚æ•°
    size_t TotalMessagesTransferred{0};  // æ€»ä¼ è¾“æ¶ˆæ¯æ•°
    size_t TotalOperationsCompleted{0};  // æ€»å®Œæˆæ“ä½œæ•°

    // Latency metrics (in microseconds)
    double MinLatencyUs{std::numeric_limits<double>::max()};  // æœ€å°å»¶è¿Ÿ
    double MaxLatencyUs{0.0};                                 // æœ€å¤§å»¶è¿Ÿ
    double AvgLatencyUs{0.0};                                 // å¹³å‡å»¶è¿Ÿ
    double MedianLatencyUs{0.0};                              // ä¸­ä½å»¶è¿Ÿ
    double P95LatencyUs{0.0};                                 // 95%åˆ†ä½å»¶è¿Ÿ
    double P99LatencyUs{0.0};                                 // 99%åˆ†ä½å»¶è¿Ÿ
    double JitterUs{0.0};                                     // å»¶è¿ŸæŠ–åŠ¨

    // Resource usage metrics
    double MemoryUsageMB{0.0};       // å†…å­˜ä½¿ç”¨é‡(MB)
    double PeakMemoryUsageMB{0.0};   // å³°å€¼å†…å­˜ä½¿ç”¨é‡(MB)
    double CPUUsagePercent{0.0};     // CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
    double AvgCPUUsagePercent{0.0};  // å¹³å‡CPUä½¿ç”¨ç‡
    size_t ThreadCount{0};           // æ´»è·ƒçº¿ç¨‹æ•°
    size_t HandleCount{0};           // å¥æŸ„æ•°é‡

    // Timing information
    std::chrono::high_resolution_clock::time_point StartTime;  // æµ‹è¯•å¼€å§‹æ—¶é—´
    std::chrono::high_resolution_clock::time_point EndTime;    // æµ‹è¯•ç»“æŸæ—¶é—´
    double DurationSeconds{0.0};                               // æµ‹è¯•æŒç»­æ—¶é—´(ç§’)

    // Quality metrics
    size_t ErrorCount{0};     // é”™è¯¯è®¡æ•°
    double ErrorRate{0.0};    // é”™è¯¯ç‡
    size_t TimeoutCount{0};   // è¶…æ—¶è®¡æ•°
    double SuccessRate{0.0};  // æˆåŠŸç‡

    // Concurrent metrics
    size_t MaxConcurrentOperations{0};  // æœ€å¤§å¹¶å‘æ“ä½œæ•°
    size_t AvgConcurrentOperations{0};  // å¹³å‡å¹¶å‘æ“ä½œæ•°
    size_t ConcurrentThreads{0};        // å¹¶å‘çº¿ç¨‹æ•°
    size_t ConcurrentConnections{0};    // å¹¶å‘è¿æ¥æ•°

} PerformanceMetrics_T;

/**
 * @brief æ€§èƒ½æµ‹è¯•é…ç½®å‚æ•°
 *        å®šä¹‰å„ç§æ€§èƒ½æµ‹è¯•çš„é…ç½®é€‰é¡¹
 */
typedef struct PerformanceTestConfig {
    // Test duration and iteration control
    std::chrono::seconds TestDurationSec{10};  // æµ‹è¯•æŒç»­æ—¶é—´
    size_t MaxIterations{1000000};             // æœ€å¤§è¿­ä»£æ¬¡æ•°
    size_t WarmupIterations{1000};             // é¢„çƒ­è¿­ä»£æ¬¡æ•°
    size_t CooldownSec{1};                     // å†·å´æ—¶é—´

    // Data transfer parameters
    size_t MinPayloadSize{64};           // æœ€å°è´Ÿè½½å¤§å°
    size_t MaxPayloadSize{1024 * 1024};  // æœ€å¤§è´Ÿè½½å¤§å°(1MB)
    size_t PayloadSizeStep{1024};        // è´Ÿè½½å¤§å°æ­¥é•¿
    std::vector<size_t> PayloadSizes;    // æŒ‡å®šçš„è´Ÿè½½å¤§å°åˆ—è¡¨

    // Concurrency parameters
    size_t MinThreadCount{1};               // æœ€å°çº¿ç¨‹æ•°
    size_t MaxThreadCount{100};             // æœ€å¤§çº¿ç¨‹æ•°
    size_t ThreadCountStep{10};             // çº¿ç¨‹æ•°æ­¥é•¿
    size_t MaxConcurrentConnections{1000};  // æœ€å¤§å¹¶å‘è¿æ¥æ•°

    // Performance targets and thresholds
    double TargetThroughputMBps{100.0};    // ç›®æ ‡ååé‡(MB/s)
    double MaxAcceptableLatencyMs{1.0};    // æœ€å¤§å¯æ¥å—å»¶è¿Ÿ(ms)
    double MaxAcceptableCPUPercent{80.0};  // æœ€å¤§å¯æ¥å—CPUä½¿ç”¨ç‡
    double MaxAcceptableMemoryMB{512.0};   // æœ€å¤§å¯æ¥å—å†…å­˜ä½¿ç”¨é‡

    // Measurement configuration
    bool EnableLatencyMeasurement{true};     // å¯ç”¨å»¶è¿Ÿæµ‹é‡
    bool EnableThroughputMeasurement{true};  // å¯ç”¨ååé‡æµ‹é‡
    bool EnableResourceMeasurement{true};    // å¯ç”¨èµ„æºä½¿ç”¨æµ‹é‡
    bool EnableDetailedLogging{false};       // å¯ç”¨è¯¦ç»†æ—¥å¿—

    // Test behavior flags
    bool UseRandomPayloadSizes{false};   // ä½¿ç”¨éšæœºè´Ÿè½½å¤§å°
    bool UseRandomTimingPattern{false};  // ä½¿ç”¨éšæœºæ—¶åºæ¨¡å¼
    bool EnableStressMode{false};        // å¯ç”¨å‹åŠ›æµ‹è¯•æ¨¡å¼
    bool EnableEnduranceMode{false};     // å¯ç”¨è€ä¹…æ€§æµ‹è¯•æ¨¡å¼

} PerformanceTestConfig_T;

/**
 * @brief æ€§èƒ½æ•°æ®é‡‡é›†å™¨
 *        å®æ—¶æ”¶é›†å’Œè®¡ç®—æ€§èƒ½æŒ‡æ ‡
 */
class PerformanceCollector {
   private:
    std::vector<double> latencySamples;
    std::mutex dataMutex;
    std::chrono::high_resolution_clock::time_point testStartTime;
    PerformanceMetrics_T currentMetrics;

   public:
    void StartCollection() {
        std::lock_guard<std::mutex> lock(dataMutex);
        testStartTime = std::chrono::high_resolution_clock::now();
        currentMetrics.StartTime = testStartTime;
        latencySamples.clear();
    }

    void RecordLatency(double latencyUs) {
        std::lock_guard<std::mutex> lock(dataMutex);
        latencySamples.push_back(latencyUs);

        // Update min/max
        if (latencyUs < currentMetrics.MinLatencyUs) {
            currentMetrics.MinLatencyUs = latencyUs;
        }
        if (latencyUs > currentMetrics.MaxLatencyUs) {
            currentMetrics.MaxLatencyUs = latencyUs;
        }
    }

    void RecordOperation(size_t bytesTransferred) {
        std::lock_guard<std::mutex> lock(dataMutex);
        currentMetrics.TotalBytesTransferred += bytesTransferred;
        currentMetrics.TotalMessagesTransferred++;
        currentMetrics.TotalOperationsCompleted++;
    }

    void RecordError() {
        std::lock_guard<std::mutex> lock(dataMutex);
        currentMetrics.ErrorCount++;
    }

    PerformanceMetrics_T FinishCollection() {
        std::lock_guard<std::mutex> lock(dataMutex);

        currentMetrics.EndTime = std::chrono::high_resolution_clock::now();
        currentMetrics.DurationSeconds =
            std::chrono::duration<double>(currentMetrics.EndTime - currentMetrics.StartTime).count();

        // Calculate throughput
        if (currentMetrics.DurationSeconds > 0) {
            currentMetrics.BytesPerSecond = currentMetrics.TotalBytesTransferred / currentMetrics.DurationSeconds;
            currentMetrics.MessagesPerSecond = currentMetrics.TotalMessagesTransferred / currentMetrics.DurationSeconds;
            currentMetrics.OperationsPerSecond =
                currentMetrics.TotalOperationsCompleted / currentMetrics.DurationSeconds;
        }

        // Calculate latency statistics
        if (!latencySamples.empty()) {
            std::sort(latencySamples.begin(), latencySamples.end());

            double sum = 0;
            for (double sample : latencySamples) {
                sum += sample;
            }
            currentMetrics.AvgLatencyUs = sum / latencySamples.size();

            size_t medianIndex = latencySamples.size() / 2;
            currentMetrics.MedianLatencyUs = latencySamples[medianIndex];

            size_t p95Index = static_cast<size_t>(latencySamples.size() * 0.95);
            if (p95Index < latencySamples.size()) {
                currentMetrics.P95LatencyUs = latencySamples[p95Index];
            }

            size_t p99Index = static_cast<size_t>(latencySamples.size() * 0.99);
            if (p99Index < latencySamples.size()) {
                currentMetrics.P99LatencyUs = latencySamples[p99Index];
            }

            // Calculate jitter (standard deviation)
            double variance = 0;
            for (double sample : latencySamples) {
                variance += (sample - currentMetrics.AvgLatencyUs) * (sample - currentMetrics.AvgLatencyUs);
            }
            currentMetrics.JitterUs = std::sqrt(variance / latencySamples.size());
        }

        // Calculate success/error rates
        size_t totalOps = currentMetrics.TotalOperationsCompleted + currentMetrics.ErrorCount;
        if (totalOps > 0) {
            currentMetrics.ErrorRate = static_cast<double>(currentMetrics.ErrorCount) / totalOps;
            currentMetrics.SuccessRate = static_cast<double>(currentMetrics.TotalOperationsCompleted) / totalOps;
        }

        return currentMetrics;
    }
};

// ===== PERFORMANCE VERIFICATION MACROS =====
/**
 * @brief æ€§èƒ½éªŒè¯å®å®šä¹‰
 *        æä¾›ä¾¿æ·çš„æ€§èƒ½æ–­è¨€å’ŒéªŒè¯åŠŸèƒ½
 */

#define VERIFY_THROUGHPUT_TARGET(metrics, targetMBps)                                                \
    do {                                                                                             \
        double actualMBps = (metrics).BytesPerSecond / (1024.0 * 1024.0);                            \
        EXPECT_GE(actualMBps, targetMBps)                                                            \
            << "Throughput below target: " << actualMBps << " MB/s < " << targetMBps << " MB/s";     \
        printf("ğŸ“Š [THROUGHPUT] Achieved: %.2f MB/s (Target: %.2f MB/s)\n", actualMBps, targetMBps); \
    } while (0)

#define VERIFY_LATENCY_TARGET(metrics, maxLatencyMs)                                                          \
    do {                                                                                                      \
        double actualLatencyMs = (metrics).AvgLatencyUs / 1000.0;                                             \
        EXPECT_LE(actualLatencyMs, maxLatencyMs)                                                              \
            << "Latency exceeds target: " << actualLatencyMs << " ms > " << maxLatencyMs << " ms";            \
        printf("â±ï¸ [LATENCY] Avg: %.3f ms, P95: %.3f ms, P99: %.3f ms (Target: < %.2f ms)\n", actualLatencyMs, \
               (metrics).P95LatencyUs / 1000.0, (metrics).P99LatencyUs / 1000.0, maxLatencyMs);               \
    } while (0)

#define VERIFY_CPU_USAGE_TARGET(metrics, maxCPUPercent)                                                        \
    do {                                                                                                       \
        EXPECT_LE((metrics).AvgCPUUsagePercent, maxCPUPercent)                                                 \
            << "CPU usage exceeds target: " << (metrics).AvgCPUUsagePercent << "% > " << maxCPUPercent << "%"; \
        printf("ğŸ’» [CPU] Usage: %.1f%% (Target: < %.1f%%)\n", (metrics).AvgCPUUsagePercent, maxCPUPercent);    \
    } while (0)

#define VERIFY_MEMORY_USAGE_TARGET(metrics, maxMemoryMB)                                                           \
    do {                                                                                                           \
        EXPECT_LE((metrics).PeakMemoryUsageMB, maxMemoryMB)                                                        \
            << "Memory usage exceeds target: " << (metrics).PeakMemoryUsageMB << " MB > " << maxMemoryMB << " MB"; \
        printf("ğŸ’¾ [MEMORY] Peak: %.1f MB, Avg: %.1f MB (Target: < %.1f MB)\n", (metrics).PeakMemoryUsageMB,       \
               (metrics).MemoryUsageMB, maxMemoryMB);                                                              \
    } while (0)

#define VERIFY_SUCCESS_RATE_TARGET(metrics, minSuccessRate)                                                            \
    do {                                                                                                               \
        EXPECT_GE((metrics).SuccessRate, minSuccessRate)                                                               \
            << "Success rate below target: " << (metrics).SuccessRate << " < " << minSuccessRate;                      \
        printf("âœ… [SUCCESS] Rate: %.2f%%, Errors: %zu/%zu (Target: > %.2f%%)\n", (metrics).SuccessRate * 100,         \
               (metrics).ErrorCount, (metrics).TotalOperationsCompleted + (metrics).ErrorCount, minSuccessRate * 100); \
    } while (0)

#define VERIFY_CONCURRENT_SCALING(baseMetrics, scaledMetrics, threadMultiplier, expectedEfficiency)                    \
    do {                                                                                                               \
        double scalingEfficiency = ((scaledMetrics).BytesPerSecond / (baseMetrics).BytesPerSecond) / threadMultiplier; \
        EXPECT_GE(scalingEfficiency, expectedEfficiency)                                                               \
            << "Concurrent scaling efficiency below target: " << scalingEfficiency << " < " << expectedEfficiency;     \
        printf("ğŸš€ [SCALING] Efficiency: %.2f%% with %dx threads (Target: > %.2f%%)\n", scalingEfficiency * 100,       \
               threadMultiplier, expectedEfficiency * 100);                                                            \
    } while (0)

// ===== PERFORMANCE TEST HELPER FUNCTIONS =====
/**
 * @brief æ€§èƒ½æµ‹è¯•è¾…åŠ©å‡½æ•°å®ç°
 *        æä¾›å¸¸ç”¨çš„æ€§èƒ½æµ‹è¯•å·¥å…·å‡½æ•°
 */

// åˆ›å»ºæ€§èƒ½æµ‹è¯•æ•°æ®
inline std::vector<char> CreatePerformanceTestData(size_t size, bool randomContent = false) {
    std::vector<char> data(size);
    if (randomContent) {
        for (size_t i = 0; i < size; ++i) {
            data[i] = static_cast<char>(rand() % 256);
        }
    } else {
        // Fill with predictable pattern for verification
        for (size_t i = 0; i < size; ++i) {
            data[i] = static_cast<char>('A' + (i % 26));
        }
    }
    return data;
}

// æµ‹é‡å•æ¬¡æ“ä½œå»¶è¿Ÿ
template <typename Func>
double MeasureOperationLatency(Func operation) {
    auto start = std::chrono::high_resolution_clock::now();
    operation();
    auto end = std::chrono::high_resolution_clock::now();
    return std::chrono::duration<double, std::micro>(end - start).count();
}

// å¹¶å‘æ‰§è¡Œæ€§èƒ½æµ‹è¯•
template <typename Func>
PerformanceMetrics_T RunConcurrentPerformanceTest(const PerformanceTestConfig_T& config, size_t threadCount,
                                                  Func threadOperation) {
    PerformanceCollector collector;
    collector.StartCollection();

    std::vector<std::thread> threads;
    std::atomic<bool> shouldStop{false};

    // å¯åŠ¨æµ‹è¯•çº¿ç¨‹
    for (size_t i = 0; i < threadCount; ++i) {
        threads.emplace_back([&, i]() { threadOperation(i, shouldStop, collector); });
    }

    // ç­‰å¾…æµ‹è¯•æ—¶é—´æˆ–è¿­ä»£å®Œæˆ
    std::this_thread::sleep_for(config.TestDurationSec);
    shouldStop = true;

    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for (auto& thread : threads) {
        thread.join();
    }

    return collector.FinishCollection();
}

// æ‰“å°æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
inline void PrintPerformanceReport(const PerformanceMetrics_T& metrics, const std::string& testName) {
    printf("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    printf("â•‘                            ğŸ“Š PERFORMANCE REPORT: %s\n", testName.c_str());
    printf("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n");
    printf("â•‘ ğŸš€ THROUGHPUT:                                                                          â•‘\n");
    printf("â•‘   â€¢ Bytes/sec:     %12.2f MB/s                                               â•‘\n",
           metrics.BytesPerSecond / (1024.0 * 1024.0));
    printf("â•‘   â€¢ Messages/sec:  %12.2f msgs/s                                             â•‘\n",
           metrics.MessagesPerSecond);
    printf("â•‘   â€¢ Operations/sec:%12.2f ops/s                                              â•‘\n",
           metrics.OperationsPerSecond);
    printf("â•‘                                                                                          â•‘\n");
    printf("â•‘ â±ï¸ LATENCY:                                                                              â•‘\n");
    printf("â•‘   â€¢ Min:           %12.2f Î¼s                                                  â•‘\n", metrics.MinLatencyUs);
    printf("â•‘   â€¢ Average:       %12.2f Î¼s                                                  â•‘\n", metrics.AvgLatencyUs);
    printf("â•‘   â€¢ Median:        %12.2f Î¼s                                                  â•‘\n",
           metrics.MedianLatencyUs);
    printf("â•‘   â€¢ P95:           %12.2f Î¼s                                                  â•‘\n", metrics.P95LatencyUs);
    printf("â•‘   â€¢ P99:           %12.2f Î¼s                                                  â•‘\n", metrics.P99LatencyUs);
    printf("â•‘   â€¢ Max:           %12.2f Î¼s                                                  â•‘\n", metrics.MaxLatencyUs);
    printf("â•‘   â€¢ Jitter:        %12.2f Î¼s                                                  â•‘\n", metrics.JitterUs);
    printf("â•‘                                                                                          â•‘\n");
    printf("â•‘ ğŸ“ˆ VOLUME:                                                                               â•‘\n");
    printf("â•‘   â€¢ Total Bytes:   %12zu bytes                                               â•‘\n",
           metrics.TotalBytesTransferred);
    printf("â•‘   â€¢ Total Messages:%12zu messages                                            â•‘\n",
           metrics.TotalMessagesTransferred);
    printf("â•‘   â€¢ Total Ops:     %12zu operations                                          â•‘\n",
           metrics.TotalOperationsCompleted);
    printf("â•‘   â€¢ Test Duration: %12.2f seconds                                            â•‘\n",
           metrics.DurationSeconds);
    printf("â•‘                                                                                          â•‘\n");
    printf("â•‘ âœ… QUALITY:                                                                              â•‘\n");
    printf("â•‘   â€¢ Success Rate:  %12.2f%%                                                   â•‘\n",
           metrics.SuccessRate * 100);
    printf("â•‘   â€¢ Error Count:   %12zu errors                                              â•‘\n", metrics.ErrorCount);
    printf("â•‘   â€¢ Error Rate:    %12.2f%%                                                   â•‘\n",
           metrics.ErrorRate * 100);
    printf("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
}

// ===== DATA TRANSFER PRIVATE DATA WITH PERFORMANCE TRACKING =====
/**
 * @brief DATæ€§èƒ½æµ‹è¯•ç§æœ‰æ•°æ®ç»“æ„
 *        æ‰©å±•åŸºç¡€çŠ¶æ€è·Ÿè¸ªï¼Œå¢åŠ æ€§èƒ½ç›‘æ§åŠŸèƒ½
 */
typedef struct __DatPerformancePrivData {
    // åŸºç¡€è¿æ¥çŠ¶æ€ (ç»§æ‰¿è‡ªDataState)
    std::atomic<bool> ServiceOnline{false};
    std::atomic<bool> LinkConnected{false};
    std::atomic<bool> StreamInitialized{false};

    // æ€§èƒ½è®¡æ•°å™¨
    std::atomic<size_t> SendOperationCount{0};
    std::atomic<size_t> RecvOperationCount{0};
    std::atomic<size_t> FlushOperationCount{0};
    std::atomic<size_t> TotalBytesSent{0};
    std::atomic<size_t> TotalBytesReceived{0};

    // å»¶è¿Ÿè¿½è¸ª
    std::vector<double> SendLatencies;
    std::vector<double> RecvLatencies;
    std::mutex LatencyMutex;

    // èµ„æºä½¿ç”¨ç›‘æ§
    std::atomic<size_t> CurrentMemoryUsage{0};
    std::atomic<size_t> PeakMemoryUsage{0};
    std::atomic<double> CurrentCPUUsage{0.0};
    std::atomic<size_t> ActiveThreadCount{0};

    // å¹¶å‘æ“ä½œè®¡æ•°
    std::atomic<size_t> ConcurrentSendOps{0};
    std::atomic<size_t> ConcurrentRecvOps{0};
    std::atomic<size_t> MaxConcurrentOps{0};

    // é”™è¯¯å’Œè¶…æ—¶è®¡æ•°
    std::atomic<size_t> ErrorCount{0};
    std::atomic<size_t> TimeoutCount{0};
    std::atomic<size_t> RetryCount{0};

    // æ€§èƒ½åŸºå‡†ç‚¹
    std::chrono::high_resolution_clock::time_point TestStartTime;
    std::chrono::high_resolution_clock::time_point LastOperationTime;

    // ä¼˜åŒ–ç‰¹æ€§æ ‡å¿—
    std::atomic<bool> BufferingEnabled{false};
    std::atomic<bool> ZeroCopyEnabled{false};
    std::atomic<bool> FlowControlActive{false};

    // æµ‹è¯•é…ç½®
    PerformanceTestConfig_T TestConfig;

} __DatPerformancePrivData_T;

/**
 * @brief é‡ç½®æ€§èƒ½æµ‹è¯•ç§æœ‰æ•°æ®
 */
inline void __ResetPerformanceTracking(__DatPerformancePrivData_T* privData) {
    if (!privData) return;

    privData->ServiceOnline = false;
    privData->LinkConnected = false;
    privData->StreamInitialized = false;

    privData->SendOperationCount = 0;
    privData->RecvOperationCount = 0;
    privData->FlushOperationCount = 0;
    privData->TotalBytesSent = 0;
    privData->TotalBytesReceived = 0;

    {
        std::lock_guard<std::mutex> lock(privData->LatencyMutex);
        privData->SendLatencies.clear();
        privData->RecvLatencies.clear();
    }

    privData->CurrentMemoryUsage = 0;
    privData->PeakMemoryUsage = 0;
    privData->CurrentCPUUsage = 0.0;
    privData->ActiveThreadCount = 0;

    privData->ConcurrentSendOps = 0;
    privData->ConcurrentRecvOps = 0;
    privData->MaxConcurrentOps = 0;

    privData->ErrorCount = 0;
    privData->TimeoutCount = 0;
    privData->RetryCount = 0;

    privData->BufferingEnabled = false;
    privData->ZeroCopyEnabled = false;
    privData->FlowControlActive = false;
}

/**
 * @brief è®°å½•æ€§èƒ½æ“ä½œ
 */
#define RECORD_PERFORMANCE_OPERATION(privData, operation, bytes, latencyUs)          \
    do {                                                                             \
        if (privData) {                                                              \
            privData->operation##OperationCount++;                                   \
            privData->TotalBytes##operation += bytes;                                \
            std::lock_guard<std::mutex> lock(privData->LatencyMutex);                \
            privData->operation##Latencies.push_back(latencyUs);                     \
            privData->LastOperationTime = std::chrono::high_resolution_clock::now(); \
        }                                                                            \
    } while (0)

/**
 * @brief æ›´æ–°å¹¶å‘æ“ä½œè®¡æ•°
 */
#define UPDATE_CONCURRENT_OPERATION_COUNT(privData, operation, increment)                                        \
    do {                                                                                                         \
        if (privData) {                                                                                          \
            if (increment) {                                                                                     \
                size_t current = ++privData->Concurrent##operation##Ops;                                         \
                size_t maxOps = privData->MaxConcurrentOps.load();                                               \
                while (current > maxOps && !privData->MaxConcurrentOps.compare_exchange_weak(maxOps, current)) { \
                }                                                                                                \
            } else {                                                                                             \
                privData->Concurrent##operation##Ops--;                                                          \
            }                                                                                                    \
        }                                                                                                        \
    } while (0)

#endif  // UT_DATAPERFORMANCE_H

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>END OF UT_DATAPERFORMANCE.H===============================================================
