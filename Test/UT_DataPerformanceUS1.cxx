///////////////////////////////////////////////////////////////////////////////////////////////////
// QUICK REFERENCE GUIDE - å¿«é€Ÿå‚è€ƒæŒ‡å—
// ğŸ“ ç”¨é€”: DATæ€§èƒ½æµ‹è¯•å•å…ƒæµ‹è¯•å®ç° - User Story 1 & 2
// ğŸ”„ æµç¨‹: User Story â†’ Acceptance Criteria â†’ Test Cases â†’ Implementation
// ğŸ“‚ åˆ†ç±»: DataPerformance US-1&2 - High throughput and low latency verification
// ğŸ¯ é‡ç‚¹: ååé‡éªŒè¯ã€å»¶è¿Ÿæµ‹é‡ã€APIæ€§èƒ½åˆ†æ
///////////////////////////////////////////////////////////////////////////////////////////////////

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF OVERVIEW OF THIS UNIT TESTING FILE===============================================
/**
 * @brief
 *  DATæ€§èƒ½æµ‹è¯•å®ç° - éªŒè¯IOCæ¡†æ¶ä¸­DATæœåŠ¡çš„æ€§èƒ½ç‰¹æ€§
 *
 *-------------------------------------------------------------------------------------------------
 *++èƒŒæ™¯è¯´æ˜ï¼š
 *  æœ¬æµ‹è¯•æ–‡ä»¶å®ç°DAT(Data Transfer)æœåŠ¡çš„æ€§èƒ½éªŒè¯
 *  é‡ç‚¹å…³æ³¨ååé‡ã€å»¶è¿Ÿç­‰å…³é”®æ€§èƒ½æŒ‡æ ‡çš„æµ‹é‡å’ŒéªŒè¯
 *  ç¡®ä¿ç³»ç»Ÿåœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç°ç¬¦åˆé¢„æœŸ
 *
 *  å…³é”®æ¦‚å¿µï¼š
 *  - Throughput Testing: ååé‡æµ‹è¯•ï¼ŒéªŒè¯æ•°æ®ä¼ è¾“é€Ÿç‡
 *  - Latency Measurement: å»¶è¿Ÿæµ‹é‡ï¼ŒéªŒè¯å“åº”æ—¶é—´ç‰¹æ€§
 *  - Performance Benchmarking: æ€§èƒ½åŸºå‡†æµ‹è¯•
 *  - Resource Monitoring: èµ„æºä½¿ç”¨ç›‘æ§
 */
//======>END OF OVERVIEW OF THIS UNIT TESTING FILE=================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//======BEGIN OF UNIT TESTING IMPLEMENTATION=======================================================

#include <gtest/gtest.h>

#include "UT_DataPerformance.h"

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>BEGIN OF TEST FIXTURE CLASS===============================================================

/**
 * @brief DATæ€§èƒ½æµ‹è¯•å¤¹å…·ç±»
 *        ä¸ºæ€§èƒ½ç›¸å…³æµ‹è¯•ç”¨ä¾‹æä¾›å…¬å…±çš„è®¾ç½®å’Œæ¸…ç†
 *        ä¸“é—¨æµ‹è¯•IOCæ¡†æ¶çš„æ€§èƒ½ç‰¹æ€§
 */
class DATPerformanceTest : public ::testing::Test {
   protected:
    void SetUp() override {
        // Initialize performance tracking
        __ResetPerformanceTracking(&senderPrivData);
        __ResetPerformanceTracking(&receiverPrivData);

        // Set default test configuration
        testConfig.TestDurationSec = std::chrono::seconds(5);
        testConfig.TargetThroughputMBps = 10.0;    // Conservative target for tests
        testConfig.MaxAcceptableLatencyMs = 10.0;  // Conservative latency target

        printf("ğŸ”§ [SETUP] DATPerformanceTest initialized\n");
    }

    void TearDown() override {
        // Clean up connections
        if (receiverLinkID != IOC_ID_INVALID) {
            IOC_closeLink(receiverLinkID);
            receiverLinkID = IOC_ID_INVALID;
        }
        if (senderLinkID != IOC_ID_INVALID) {
            IOC_closeLink(senderLinkID);
            senderLinkID = IOC_ID_INVALID;
        }
        if (testSrvID != IOC_ID_INVALID) {
            IOC_offlineService(testSrvID);
            testSrvID = IOC_ID_INVALID;
        }

        printf("ğŸ§¹ [TEARDOWN] DATPerformanceTest cleaned up\n");
    }

    // Helper method to setup performance test scenario
    void setupPerformanceTestScenario() {
        // Setup Service as DatSender
        IOC_SrvArgs_T srvArgs = {};
        IOC_Helper_initSrvArgs(&srvArgs);
        srvArgs.SrvURI.pProtocol = IOC_SRV_PROTO_FIFO;
        srvArgs.SrvURI.pHost = IOC_SRV_HOST_LOCAL_PROCESS;
        srvArgs.SrvURI.pPath = "test/performance/scenario";
        srvArgs.UsageCapabilites = IOC_LinkUsageDatSender;
        srvArgs.Flags = IOC_SRVFLAG_AUTO_ACCEPT;

        IOC_Result_T result = IOC_onlineService(&testSrvID, &srvArgs);
        ASSERT_EQ(IOC_RESULT_SUCCESS, result) << "Service setup failed";

        // Setup Client connection as DatReceiver
        IOC_ConnArgs_T connArgs = {};
        IOC_Helper_initConnArgs(&connArgs);
        connArgs.SrvURI = srvArgs.SrvURI;
        connArgs.Usage = IOC_LinkUsageDatReceiver;

        result = IOC_connectService(&receiverLinkID, &connArgs, NULL);
        ASSERT_EQ(IOC_RESULT_SUCCESS, result) << "Client connection setup failed";

        senderLinkID = receiverLinkID;  // Same link for bi-directional testing

        // Update state tracking
        senderPrivData.ServiceOnline = true;
        senderPrivData.LinkConnected = true;
        receiverPrivData.LinkConnected = true;
    }

    // Test data members
    __DatPerformancePrivData_T senderPrivData;
    __DatPerformancePrivData_T receiverPrivData;
    PerformanceTestConfig_T testConfig;
    IOC_SrvID_T testSrvID = IOC_ID_INVALID;
    IOC_LinkID_T senderLinkID = IOC_ID_INVALID;
    IOC_LinkID_T receiverLinkID = IOC_ID_INVALID;
};

//======>END OF TEST FIXTURE CLASS=================================================================

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>US-1 AC-1 TESTS: High-throughput bulk data transfer======================================

/**
 * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
 * â•‘                           ğŸš€ BULK DATA THROUGHPUT VERIFICATION                          â•‘
 * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
 * â•‘ @[Name]: verifyBulkDataThroughput_byLargePayloads_expectOptimalRates                    â•‘
 * â•‘ @[Purpose]: éªŒè¯å¤§è´Ÿè½½æ•°æ®ä¼ è¾“çš„ååé‡æ€§èƒ½                                               â•‘
 * â•‘ @[Steps]: ä½¿ç”¨1KBåˆ°1MBè´Ÿè½½æµ‹è¯•ååé‡ï¼ŒéªŒè¯æ€§èƒ½ç›®æ ‡è¾¾æˆ                                  â•‘
 * â•‘ @[Expect]: ååé‡è¾¾åˆ°ç›®æ ‡å€¼ï¼Œæ€§èƒ½éšè´Ÿè½½å¤§å°åˆç†æ‰©å±•                                      â•‘
 * â•‘ @[Notes]: è¿™æ˜¯æ€§èƒ½æµ‹è¯•çš„æ ¸å¿ƒç”¨ä¾‹                                                        â•‘
 * â•‘                                                                                          â•‘
 * â•‘ ğŸ¯ Throughputæµ‹è¯•é‡ç‚¹ï¼š                                                                 â•‘
 * â•‘   â€¢ éªŒè¯æœ€å¤§æ•°æ®ä¼ è¾“é€Ÿç‡                                                                 â•‘
 * â•‘   â€¢ ç¡®ä¿æ€§èƒ½éšè´Ÿè½½å¤§å°çš„åˆç†æ‰©å±•                                                         â•‘
 * â•‘   â€¢ æµ‹è¯•æ‰¹é‡ä¼ è¾“çš„æ•ˆç‡                                                                   â•‘
 * â•‘ @[TestPattern]: US-1 AC-1 TC-1 - é«˜ååé‡æ•°æ®ä¼ è¾“éªŒè¯                                  â•‘
 * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */
TEST_F(DATPerformanceTest, verifyBulkDataThroughput_byLargePayloads_expectOptimalRates) {
    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                                ğŸ”§ SETUP PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    printf("ğŸ§ª [TEST] verifyBulkDataThroughput_byLargePayloads_expectOptimalRates\n");

    setupPerformanceTestScenario();

    ASSERT_TRUE(senderPrivData.LinkConnected.load()) << "Sender link should be connected";

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                               ğŸ¯ BEHAVIOR PHASE                                       â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    printf("ğŸš€ [ACTION] Testing bulk data throughput with large payloads\n");

    PerformanceCollector collector;
    collector.StartCollection();

    // Test different payload sizes
    std::vector<size_t> payloadSizes = {1024, 4096, 16384, 65536, 262144};  // 1KB to 256KB

    for (size_t payloadSize : payloadSizes) {
        printf("ğŸ“Š [PAYLOAD] Testing with %zu bytes\n", payloadSize);

        // Create test data
        std::vector<char> testData = CreatePerformanceTestData(payloadSize, false);

        // Measure throughput for this payload size
        auto startTime = std::chrono::high_resolution_clock::now();
        size_t iterations = 100;  // Fixed number for consistent testing

        for (size_t i = 0; i < iterations; ++i) {
            IOC_DatDesc_T sendDesc = {};
            IOC_initDatDesc(&sendDesc);
            sendDesc.Payload.pData = testData.data();
            sendDesc.Payload.PtrDataSize = payloadSize;
            sendDesc.Payload.PtrDataLen = payloadSize;

            auto opStart = std::chrono::high_resolution_clock::now();
            IOC_Result_T result = IOC_sendDAT(senderLinkID, &sendDesc, NULL);
            auto opEnd = std::chrono::high_resolution_clock::now();

            if (result == IOC_RESULT_SUCCESS) {
                double latencyUs = std::chrono::duration<double, std::micro>(opEnd - opStart).count();
                collector.RecordLatency(latencyUs);
                collector.RecordOperation(payloadSize);

                // Update private data tracking
                senderPrivData.SendOperationCount++;
                senderPrivData.TotalBytesSent += payloadSize;
                {
                    std::lock_guard<std::mutex> lock(senderPrivData.LatencyMutex);
                    senderPrivData.SendLatencies.push_back(latencyUs);
                }
            } else {
                collector.RecordError();
                printf("âš ï¸ [WARNING] IOC_sendDAT failed with result %d for iteration %zu\n", result, i);
            }

            // Small delay to prevent overwhelming the system
            std::this_thread::sleep_for(std::chrono::microseconds(100));
        }

        auto endTime = std::chrono::high_resolution_clock::now();
        double durationSec = std::chrono::duration<double>(endTime - startTime).count();

        // Calculate and display throughput for this payload size
        double mbps = (iterations * payloadSize) / (durationSec * 1024.0 * 1024.0);
        printf("ğŸ“ˆ [RESULT] Payload %zu bytes: %.2f MB/s over %.3f seconds\n", payloadSize, mbps, durationSec);
    }

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                                âœ… VERIFY PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    PerformanceMetrics_T metrics = collector.FinishCollection();

    // Print comprehensive performance report
    PrintPerformanceReport(metrics, "Bulk Data Throughput Test");

    // @KeyVerifyPoint-1: Overall throughput should meet target
    VERIFY_THROUGHPUT_TARGET(metrics, testConfig.TargetThroughputMBps);

    // @KeyVerifyPoint-2: Success rate should be high
    VERIFY_SUCCESS_RATE_TARGET(metrics, 0.95);  // 95% success rate

    // @KeyVerifyPoint-3: Latency should be reasonable
    VERIFY_LATENCY_TARGET(metrics, testConfig.MaxAcceptableLatencyMs);

    // @KeyVerifyPoint-4: Verify performance data was collected
    ASSERT_GT(senderPrivData.SendOperationCount.load(), 0) << "Should have recorded send operations";
    ASSERT_GT(senderPrivData.TotalBytesSent.load(), 0) << "Should have sent some data";

    printf("âœ… [SUCCESS] Bulk data throughput test completed\n");
    printf("ğŸ“Š [SUMMARY] Sent %zu bytes in %zu operations\n", senderPrivData.TotalBytesSent.load(),
           senderPrivData.SendOperationCount.load());

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                               ğŸ§¹ CLEANUP PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    // Cleanup handled by TearDown()
}

/**
 * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
 * â•‘                          â±ï¸ API RESPONSE TIME VERIFICATION                               â•‘
 * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
 * â•‘ @[Name]: verifyAPIResponseTime_byCallLatency_expectMicrosecondLevel                     â•‘
 * â•‘ @[Purpose]: éªŒè¯APIè°ƒç”¨å“åº”æ—¶é—´                                                         â•‘
 * â•‘ @[Steps]: æµ‹é‡IOC_sendDAT/IOC_recvDATçš„APIè°ƒç”¨å»¶è¿Ÿ                                      â•‘
 * â•‘ @[Expect]: APIå»¶è¿Ÿåœ¨å¾®ç§’çº§åˆ«ï¼Œæ€§èƒ½ç¨³å®š                                                   â•‘
 * â•‘ @[Notes]: ä¸“é—¨æµ‹è¯•APIçº§åˆ«çš„æ€§èƒ½ç‰¹æ€§                                                     â•‘
 * â•‘                                                                                          â•‘
 * â•‘ ğŸ¯ APIæ€§èƒ½æµ‹è¯•é‡ç‚¹ï¼š                                                                    â•‘
 * â•‘   â€¢ éªŒè¯APIè°ƒç”¨çš„å“åº”æ—¶é—´                                                               â•‘
 * â•‘   â€¢ ç¡®ä¿ä½å»¶è¿Ÿè¦æ±‚çš„æ»¡è¶³                                                                â•‘
 * â•‘   â€¢ æµ‹è¯•APIæ€§èƒ½çš„ä¸€è‡´æ€§                                                                 â•‘
 * â•‘ @[TestPattern]: US-2 AC-2 TC-2 - APIå“åº”æ—¶é—´éªŒè¯                                      â•‘
 * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */
TEST_F(DATPerformanceTest, verifyAPIResponseTime_byCallLatency_expectMicrosecondLevel) {
    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                                ğŸ”§ SETUP PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    printf("ğŸ§ª [TEST] verifyAPIResponseTime_byCallLatency_expectMicrosecondLevel\n");

    setupPerformanceTestScenario();

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                               ğŸ¯ BEHAVIOR PHASE                                       â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    printf("â±ï¸ [ACTION] Measuring API call latency for small messages\n");

    PerformanceCollector collector;
    collector.StartCollection();

    // Test small message latency
    const size_t messageSize = 256;  // Small message for latency testing
    std::vector<char> testData = CreatePerformanceTestData(messageSize, false);

    const size_t testIterations = 1000;
    std::vector<double> apiLatencies;

    for (size_t i = 0; i < testIterations; ++i) {
        IOC_DatDesc_T sendDesc = {};
        IOC_initDatDesc(&sendDesc);
        sendDesc.Payload.pData = testData.data();
        sendDesc.Payload.PtrDataSize = messageSize;
        sendDesc.Payload.PtrDataLen = messageSize;

        // Measure API call latency precisely
        double latencyUs = MeasureOperationLatency([&]() {
            IOC_Result_T result = IOC_sendDAT(senderLinkID, &sendDesc, NULL);
            if (result != IOC_RESULT_SUCCESS) {
                collector.RecordError();
            }
        });

        apiLatencies.push_back(latencyUs);
        collector.RecordLatency(latencyUs);
        collector.RecordOperation(messageSize);

        // Update performance tracking
        senderPrivData.SendOperationCount++;
        senderPrivData.TotalBytesSent += messageSize;
        {
            std::lock_guard<std::mutex> lock(senderPrivData.LatencyMutex);
            senderPrivData.SendLatencies.push_back(latencyUs);
        }

        // Brief pause to prevent overwhelming
        if (i % 100 == 0) {
            std::this_thread::sleep_for(std::chrono::microseconds(10));
        }
    }

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                                âœ… VERIFY PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    PerformanceMetrics_T metrics = collector.FinishCollection();

    // Print detailed latency analysis
    printf("\nğŸ“Š [LATENCY ANALYSIS]\n");
    printf("â”œâ”€ Iterations: %zu\n", testIterations);
    printf("â”œâ”€ Message Size: %zu bytes\n", messageSize);
    printf("â”œâ”€ Min Latency: %.2f Î¼s\n", metrics.MinLatencyUs);
    printf("â”œâ”€ Max Latency: %.2f Î¼s\n", metrics.MaxLatencyUs);
    printf("â”œâ”€ Avg Latency: %.2f Î¼s\n", metrics.AvgLatencyUs);
    printf("â”œâ”€ Median Latency: %.2f Î¼s\n", metrics.MedianLatencyUs);
    printf("â”œâ”€ P95 Latency: %.2f Î¼s\n", metrics.P95LatencyUs);
    printf("â”œâ”€ P99 Latency: %.2f Î¼s\n", metrics.P99LatencyUs);
    printf("â””â”€ Jitter (StdDev): %.2f Î¼s\n", metrics.JitterUs);

    // @KeyVerifyPoint-1: Average latency should be low
    double avgLatencyMs = metrics.AvgLatencyUs / 1000.0;
    EXPECT_LE(avgLatencyMs, testConfig.MaxAcceptableLatencyMs)
        << "Average API latency too high: " << avgLatencyMs << " ms";

    // @KeyVerifyPoint-2: P99 latency should be reasonable
    double p99LatencyMs = metrics.P99LatencyUs / 1000.0;
    EXPECT_LE(p99LatencyMs, testConfig.MaxAcceptableLatencyMs * 2)
        << "P99 API latency too high: " << p99LatencyMs << " ms";

    // @KeyVerifyPoint-3: Jitter should be minimal
    double jitterMs = metrics.JitterUs / 1000.0;
    EXPECT_LE(jitterMs, testConfig.MaxAcceptableLatencyMs) << "API latency jitter too high: " << jitterMs << " ms";

    // @KeyVerifyPoint-4: Success rate should be very high for API calls
    VERIFY_SUCCESS_RATE_TARGET(metrics, 0.99);  // 99% success rate expected

    printf("âœ… [SUCCESS] API response time test completed\n");
    printf("ğŸ“Š [SUMMARY] %zu API calls with avg latency %.2f Î¼s\n", testIterations, metrics.AvgLatencyUs);

    // â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    // â”‚                               ğŸ§¹ CLEANUP PHASE                                        â”‚
    // â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    // Cleanup handled by TearDown()
}

///////////////////////////////////////////////////////////////////////////////////////////////////
//======>END OF US-1&2 IMPLEMENTATION==============================================================
